{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G95nVHN4yZpo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMg410WwzbRo",
        "outputId": "57661eba-235b-4793-a5db-75b9a36a6c1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers==4.16\n",
        "%pip install arabert\n",
        "%pip install farasapy\n",
        "%pip install pyarabic==0.6.14\n",
        "%pip install sentencepiece==0.1.96"
      ],
      "metadata": {
        "id": "e8sDvWZpkwV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                             confusion_matrix, f1_score, precision_score,\n",
        "                             recall_score)\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer, BertTokenizer, Trainer,\n",
        "                          TrainingArguments)\n",
        "from transformers.data.processors.utils import InputFeatures"
      ],
      "metadata": {
        "id": "wie9GyO0ky1B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, text, target, model_name, max_len, label_map):\n",
        "      super(ClassificationDataset).__init__()\n",
        "      \"\"\"\n",
        "      Args:\n",
        "      text (List[str]): List of the training text\n",
        "      target (List[str]): List of the training labels\n",
        "      tokenizer_name (str): The tokenizer name (same as model_name).\n",
        "      max_len (int): Maximum sentence length\n",
        "      \"\"\"\n",
        "      self.text = text\n",
        "      self.target = target\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "\n",
        "      inputs = self.tokenizer(\n",
        "          text,\n",
        "          max_length=self.max_len,\n",
        "          padding='max_length',\n",
        "          truncation=True\n",
        "      )\n",
        "      return InputFeatures(**inputs,label=self.label_map[self.target[item]])"
      ],
      "metadata": {
        "id": "ROAbx2AEk4v0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4VU-wCKyZps"
      },
      "source": [
        "## Data Preprocessing and Translating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq-5vx-KyZpt"
      },
      "outputs": [],
      "source": [
        "# ar_ht_en_tune = open('Arab-Acquis/Arabic-Translations/tune.en_ref.ar').read().splitlines()\n",
        "# ar_ht_en_dev = open('Arab-Acquis/Arabic-Translations/dev.en_ref.ar').read().splitlines()\n",
        "\n",
        "# ar_ht_fr_tune = open('Arab-Acquis/Arabic-Translations/tune.fr_ref.ar').read().splitlines()\n",
        "# ar_ht_fr_dev = open('Arab-Acquis/Arabic-Translations/dev.fr_ref.ar').read().splitlines()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbldqji1yZpu"
      },
      "outputs": [],
      "source": [
        "# get the arabic sentences from the dataset (HT)\n",
        "# ar_ht_en_tune = pd.DataFrame(ar_ht_en_tune, columns=['sentences'])\n",
        "\n",
        "# ar_ht_en_dev = pd.DataFrame(ar_ht_en_dev, columns=['sentences'])\n",
        "\n",
        "\n",
        "# ar_ht_fr_tune = pd.DataFrame(ar_ht_fr_tune, columns=['sentences'])\n",
        "\n",
        "# ar_ht_fr_dev = pd.DataFrame(ar_ht_fr_dev, columns=['sentences'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzzywbADyZpu"
      },
      "outputs": [],
      "source": [
        "# get english and french data to translate\n",
        "# en_tune = open('Arab-Acquis/JRC-Acquis/ac-dev.en').read().splitlines()\n",
        "# en_dev = open('Arab-Acquis/JRC-Acquis/ac-devtest.en').read().splitlines()\n",
        "\n",
        "# fr_tune = open('Arab-Acquis/JRC-Acquis/ac-dev.fr').read().splitlines()\n",
        "# fr_dev = open('Arab-Acquis/JRC-Acquis/ac-devtest.fr').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeCJuCaWyZpu"
      },
      "outputs": [],
      "source": [
        "# %pip install googletrans==4.0.0rc1\n",
        "# %pip install -U deep-translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlcmtdLLyZpv"
      },
      "outputs": [],
      "source": [
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "from deep_translator import GoogleTranslator\n",
        "deep_translator = GoogleTranslator(source='fr', target='ar')\n",
        "\n",
        "#googletrans stopped working (API issues) so I used deep_translator instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9KTyKeryZpv"
      },
      "outputs": [],
      "source": [
        "# translate to arabic\n",
        "ar_mt_en_tune = []\n",
        "for i in range(len(en_tune)):\n",
        "    ar_mt_en_tune.append(deep_translator.translate(en_tune[i]))\n",
        "\n",
        "ar_mt_en_dev = []\n",
        "for i in range(len(en_dev)):\n",
        "    ar_mt_en_dev.append(deep_translator.translate(en_dev[i]))\n",
        "\n",
        "ar_mt_fr_tune = []\n",
        "for i in range(len(fr_tune)):\n",
        "    ar_mt_fr_tune.append(deep_translator.translate(fr_tune[i]))\n",
        "\n",
        "ar_mt_fr_dev = []\n",
        "for i in range(len(fr_dev)):\n",
        "    ar_mt_fr_dev.append(deep_translator.translate(fr_dev[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBJa2huJyZpv"
      },
      "outputs": [],
      "source": [
        "# make dataframes\n",
        "ar_en_tune = pd.DataFrame({'en': en_tune, 'ar_mt': ar_mt_en_tune, 'ar_ht': ar_ht_en_tune})\n",
        "ar_en_dev = pd.DataFrame({'en': en_dev, 'ar_mt': ar_mt_en_dev, 'ar_ht': ar_ht_en_dev})\n",
        "ar_fr_tune = pd.DataFrame({'fr': fr_tune, 'ar_mt': ar_mt_fr_tune, 'ar_ht': ar_ht_fr_tune})\n",
        "ar_fr_dev = pd.DataFrame({'fr': fr_dev, 'ar_mt': ar_mt_fr_dev, 'ar_ht': ar_ht_fr_dev})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHMa_K1-yZpw"
      },
      "outputs": [],
      "source": [
        "#delete repeated english/french rows\n",
        "ar_en_tune = ar_en_tune.drop_duplicates(subset=['en'])\n",
        "ar_en_dev = ar_en_dev.drop_duplicates(subset=['en'])\n",
        "ar_fr_tune = ar_fr_tune.drop_duplicates(subset=['fr'])\n",
        "ar_fr_dev = ar_fr_dev.drop_duplicates(subset=['fr'])\n",
        "\n",
        "#delete the rows where mt is the same as ht\n",
        "ar_en_tune = ar_en_tune[ar_en_tune['ar_mt'] != ar_en_tune['ar_ht']]\n",
        "ar_en_dev = ar_en_dev[ar_en_dev['ar_mt'] != ar_en_dev['ar_ht']]\n",
        "ar_fr_tune = ar_fr_tune[ar_fr_tune['ar_mt'] != ar_fr_tune['ar_ht']]\n",
        "ar_fr_dev = ar_fr_dev[ar_fr_dev['ar_mt'] != ar_fr_dev['ar_ht']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JxZ7aroyZpw"
      },
      "outputs": [],
      "source": [
        "#save the dataframes\n",
        "ar_en_tune.to_csv('ar_en_tune_filtered.csv', index=False)\n",
        "ar_en_dev.to_csv('ar_en_dev_filtered.csv', index=False)\n",
        "ar_fr_tune.to_csv('ar_fr_tune_filtered.csv', index=False)\n",
        "ar_fr_dev.to_csv('ar_fr_dev_filterd.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo-UMLsAyZpw"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wa2zUG1kyZpw"
      },
      "outputs": [],
      "source": [
        "#import data\n",
        "ar_en_tune = pd.read_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/ar_en_tune_filtered.csv')\n",
        "ar_en_dev = pd.read_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/ar_en_dev_filtered.csv')\n",
        "ar_fr_tune = pd.read_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/ar_fr_tune_filtered.csv')\n",
        "ar_fr_dev = pd.read_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/ar_fr_dev_filterd.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eXjwXEo6Zvnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Smwnfr_yZpx"
      },
      "outputs": [],
      "source": [
        "## combine tune and dev and split into train and dev 20%\n",
        "ar_en = pd.concat([ar_en_tune, ar_en_dev])\n",
        "ar_fr = pd.concat([ar_fr_tune, ar_fr_dev])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "ar_en_train, ar_en_dev = train_test_split(ar_en, test_size=0.2, random_state=42)\n",
        "ar_fr_train, ar_fr_dev = train_test_split(ar_fr, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "4P6dvsUTyZpx",
        "outputId": "fab9df53-f7f8-4849-982d-e8e993688628"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3824c4928060>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_en_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_en_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_fr_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_fr_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ar_en_train' is not defined"
          ]
        }
      ],
      "source": [
        "len(ar_en_train), len(ar_en_dev), len(ar_fr_train), len(ar_fr_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBJPp_xEyZpz",
        "outputId": "e8d988d4-be26-4f85-c02d-62fc459a6c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'farasa-api.qcri.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 241M/241M [00:25<00:00, 9.62MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-11-24 08:00:21,100 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ],
      "source": [
        "#import and define arabert preprocessor\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "# model_name = 'aubmindlab/bert-base-arabertv2'\n",
        "model_name = 'aubmindlab/bert-base-arabertv2'\n",
        "arabic_prep = ArabertPreprocessor(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_YWhljWyZp0"
      },
      "outputs": [],
      "source": [
        "#\n",
        "tok = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_97u32Z5yZp0"
      },
      "outputs": [],
      "source": [
        "max_len = 160\n",
        "label_map = {0: 0, 1: 1}\n",
        "train_dataset = ClassificationDataset(\n",
        "    np.concatenate((ar_en_train['ar_ht'], ar_en_train['ar_mt'], ar_fr_train['ar_ht'], ar_fr_train['ar_mt']), axis=0).tolist(),\n",
        "    np.concatenate((np.zeros(len(ar_en_train)), np.ones(len(ar_en_train)), np.zeros(len(ar_fr_train)), np.ones(len(ar_fr_train))), axis=0).tolist(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )\n",
        "test_dataset = ClassificationDataset(\n",
        "    np.concatenate((ar_en_dev['ar_ht'], ar_en_dev['ar_mt'], ar_fr_dev['ar_ht'], ar_fr_dev['ar_mt']), axis=0).tolist(),\n",
        "    np.concatenate((np.zeros(len(ar_en_dev)), np.ones(len(ar_en_dev)), np.zeros(len(ar_fr_dev)), np.ones(len(ar_fr_dev))), axis=0).tolist(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqn1ZEQ5yZp1"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXpFDvhFyZp1"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  assert len(preds) == len(p.label_ids)\n",
        "  print(classification_report(p.label_ids,preds))\n",
        "  print(confusion_matrix(p.label_ids,preds))\n",
        "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "  macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "  macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "  acc = accuracy_score(p.label_ids,preds)\n",
        "  return {\n",
        "      'macro_f1' : macro_f1,\n",
        "      'accuracy': acc,\n",
        "      'macro_precision': macro_precision,\n",
        "      'macro_recall': macro_recall\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkX9BDp3yZp1"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic=True\n",
        "  torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Rate"
      ],
      "metadata": {
        "id": "Uk8rZV4kggoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lr = 1e-5"
      ],
      "metadata": {
        "id": "_wuppc3Kqqgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJp0F3j2yZp1"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= \"/content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 1e-5,\n",
        "    fp16 = False, # enable this when using V100 or T4 GPU\n",
        "    per_device_train_batch_size = 16, # up to 64 on 16GB with max len of 128\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n",
        "    num_train_epochs= 4,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 25\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "64aebaff460e4d09aca4b242e2d04b48",
            "ed1d06ab6db94318aa341f460abda3dc",
            "3b407842f2e44fc88ddb39bd6c571b6c",
            "c79cb1bef7dc438d846365ce463cd050",
            "71ea323b4ca0478f946ab1c8dd2d84e7",
            "46e992226d9b492b91431f3854e6d409",
            "a50d3df77de54a00b412a5a747aaaebc",
            "1ecdc6f7d73a417889907d73130e47e8",
            "38e95a1fc5d54ae7828c6175bd617829",
            "4930cb71498b4436af100e0d0f92cca7",
            "82d0ea92ab924db285ff061c5f8697a1"
          ]
        },
        "id": "lgh1s-5ayZp1",
        "outputId": "c8333b66-34e0-4fea-8ec2-daa698f11560"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64aebaff460e4d09aca4b242e2d04b48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJlYplzYyZp1",
        "outputId": "e9a86e68-eb72-45b1-db1e-ec272bdf7a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 20230\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 2528\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2528' max='2528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2528/2528 36:35, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.564800</td>\n",
              "      <td>0.448688</td>\n",
              "      <td>0.777609</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.781563</td>\n",
              "      <td>0.778261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.449000</td>\n",
              "      <td>0.399578</td>\n",
              "      <td>0.799970</td>\n",
              "      <td>0.800791</td>\n",
              "      <td>0.805806</td>\n",
              "      <td>0.800791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.383000</td>\n",
              "      <td>0.410585</td>\n",
              "      <td>0.804920</td>\n",
              "      <td>0.806719</td>\n",
              "      <td>0.818471</td>\n",
              "      <td>0.806719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.313800</td>\n",
              "      <td>0.399233</td>\n",
              "      <td>0.812511</td>\n",
              "      <td>0.813439</td>\n",
              "      <td>0.819770</td>\n",
              "      <td>0.813439</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.72      0.77      2530\n",
            "           1       0.75      0.83      0.79      2530\n",
            "\n",
            "    accuracy                           0.78      5060\n",
            "   macro avg       0.78      0.78      0.78      5060\n",
            "weighted avg       0.78      0.78      0.78      5060\n",
            "\n",
            "[[1832  698]\n",
            " [ 424 2106]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-632\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-632/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-632/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.74      0.79      2530\n",
            "           1       0.77      0.86      0.81      2530\n",
            "\n",
            "    accuracy                           0.80      5060\n",
            "   macro avg       0.81      0.80      0.80      5060\n",
            "weighted avg       0.81      0.80      0.80      5060\n",
            "\n",
            "[[1864  666]\n",
            " [ 342 2188]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-1264\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-1264/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-1264/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.71      0.79      2530\n",
            "           1       0.76      0.90      0.82      2530\n",
            "\n",
            "    accuracy                           0.81      5060\n",
            "   macro avg       0.82      0.81      0.80      5060\n",
            "weighted avg       0.82      0.81      0.80      5060\n",
            "\n",
            "[[1798  732]\n",
            " [ 246 2284]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-1896\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-1896/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-1896/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80      2530\n",
            "           1       0.77      0.88      0.83      2530\n",
            "\n",
            "    accuracy                           0.81      5060\n",
            "   macro avg       0.82      0.81      0.81      5060\n",
            "weighted avg       0.82      0.81      0.81      5060\n",
            "\n",
            "[[1880  650]\n",
            " [ 294 2236]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-2528\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-2528/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-2528/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr1/checkpoint-2528 (score: 0.8125106763532592).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2528, training_loss=0.4100747746002825, metrics={'train_runtime': 2199.4256, 'train_samples_per_second': 36.791, 'train_steps_per_second': 1.149, 'total_flos': 6652927479187200.0, 'train_loss': 0.4100747746002825, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lr = 2e-5\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"/content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 2e-5,\n",
        "    fp16 = True, # enable this when using V100 or T4 GPU\n",
        "    per_device_train_batch_size = 16, # up to 64 on 16GB with max len of 128\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n",
        "    num_train_epochs= 4,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 25\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duPYET2mq2wB",
        "outputId": "4d712ea8-68e4-41a2-f404-d8b8586a0be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NCal4ocOrK8h",
        "outputId": "e459f598-9bda-4f3b-85f8-75e48e0edd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 20230\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 2528\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2528' max='2528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2528/2528 14:14, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.531500</td>\n",
              "      <td>0.425188</td>\n",
              "      <td>0.796691</td>\n",
              "      <td>0.796838</td>\n",
              "      <td>0.797698</td>\n",
              "      <td>0.796838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.396900</td>\n",
              "      <td>0.370225</td>\n",
              "      <td>0.821578</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822905</td>\n",
              "      <td>0.821739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.380415</td>\n",
              "      <td>0.829076</td>\n",
              "      <td>0.830040</td>\n",
              "      <td>0.837657</td>\n",
              "      <td>0.830040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.230100</td>\n",
              "      <td>0.394040</td>\n",
              "      <td>0.836347</td>\n",
              "      <td>0.836759</td>\n",
              "      <td>0.840188</td>\n",
              "      <td>0.836759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.82      0.80      2530\n",
            "           1       0.81      0.77      0.79      2530\n",
            "\n",
            "    accuracy                           0.80      5060\n",
            "   macro avg       0.80      0.80      0.80      5060\n",
            "weighted avg       0.80      0.80      0.80      5060\n",
            "\n",
            "[[2084  446]\n",
            " [ 582 1948]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-632\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-632/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-632/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.79      0.82      2530\n",
            "           1       0.80      0.85      0.83      2530\n",
            "\n",
            "    accuracy                           0.82      5060\n",
            "   macro avg       0.82      0.82      0.82      5060\n",
            "weighted avg       0.82      0.82      0.82      5060\n",
            "\n",
            "[[2003  527]\n",
            " [ 375 2155]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-1264\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-1264/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-1264/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.75      0.82      2530\n",
            "           1       0.79      0.91      0.84      2530\n",
            "\n",
            "    accuracy                           0.83      5060\n",
            "   macro avg       0.84      0.83      0.83      5060\n",
            "weighted avg       0.84      0.83      0.83      5060\n",
            "\n",
            "[[1910  620]\n",
            " [ 240 2290]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-1896\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-1896/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-1896/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.79      0.83      2530\n",
            "           1       0.81      0.89      0.84      2530\n",
            "\n",
            "    accuracy                           0.84      5060\n",
            "   macro avg       0.84      0.84      0.84      5060\n",
            "weighted avg       0.84      0.84      0.84      5060\n",
            "\n",
            "[[1990  540]\n",
            " [ 286 2244]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-2528\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-2528/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-2528/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr2/checkpoint-2528 (score: 0.8363465189276169).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2528, training_loss=0.3478207041191149, metrics={'train_runtime': 854.811, 'train_samples_per_second': 94.664, 'train_steps_per_second': 2.957, 'total_flos': 6652927479187200.0, 'train_loss': 0.3478207041191149, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lr = 3e-5\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"/content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 3e-5,\n",
        "    fp16 = True, # enable this when using V100 or T4 GPU\n",
        "    per_device_train_batch_size = 16, # up to 64 on 16GB with max len of 128\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n",
        "    num_train_epochs= 4,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 25\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_xbt-iJujkK",
        "outputId": "4a8b6019-770c-4ccf-f011-b7cc986980fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndk-_cwvuq3-",
        "outputId": "3618f920-9db4-4eb0-8b04-37a3baf89ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fcf7a61cc072840ad32e1a2e8eb230a79b33db68e3f965f8014a52915cab999f.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv2\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/da598d10a62ed68f0b95e0c032d813a008518ba8fe1d02fb191884f844c818ce.97462e17e0f13709a0a977021298c2733cda0cb6787facbeeb0b53199a7e73bf\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6stCwJnGutqL",
        "outputId": "3a4f8cbc-c1c0-427e-cb47-cb9253d444c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 20230\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 2528\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2528' max='2528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2528/2528 14:15, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.525400</td>\n",
              "      <td>0.424446</td>\n",
              "      <td>0.793108</td>\n",
              "      <td>0.793281</td>\n",
              "      <td>0.794261</td>\n",
              "      <td>0.793281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.398500</td>\n",
              "      <td>0.363673</td>\n",
              "      <td>0.823239</td>\n",
              "      <td>0.823518</td>\n",
              "      <td>0.825573</td>\n",
              "      <td>0.823518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.307300</td>\n",
              "      <td>0.379270</td>\n",
              "      <td>0.831924</td>\n",
              "      <td>0.832609</td>\n",
              "      <td>0.838120</td>\n",
              "      <td>0.832609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.204700</td>\n",
              "      <td>0.403617</td>\n",
              "      <td>0.838886</td>\n",
              "      <td>0.839328</td>\n",
              "      <td>0.843092</td>\n",
              "      <td>0.839328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.82      0.80      2530\n",
            "           1       0.81      0.76      0.79      2530\n",
            "\n",
            "    accuracy                           0.79      5060\n",
            "   macro avg       0.79      0.79      0.79      5060\n",
            "weighted avg       0.79      0.79      0.79      5060\n",
            "\n",
            "[[2080  450]\n",
            " [ 596 1934]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-632\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-632/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-632/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.82      2530\n",
            "           1       0.80      0.86      0.83      2530\n",
            "\n",
            "    accuracy                           0.82      5060\n",
            "   macro avg       0.83      0.82      0.82      5060\n",
            "weighted avg       0.83      0.82      0.82      5060\n",
            "\n",
            "[[1983  547]\n",
            " [ 346 2184]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-1264\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-1264/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-1264/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.77      0.82      2530\n",
            "           1       0.79      0.90      0.84      2530\n",
            "\n",
            "    accuracy                           0.83      5060\n",
            "   macro avg       0.84      0.83      0.83      5060\n",
            "weighted avg       0.84      0.83      0.83      5060\n",
            "\n",
            "[[1945  585]\n",
            " [ 262 2268]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-1896\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-1896/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-1896/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.79      0.83      2530\n",
            "           1       0.81      0.89      0.85      2530\n",
            "\n",
            "    accuracy                           0.84      5060\n",
            "   macro avg       0.84      0.84      0.84      5060\n",
            "weighted avg       0.84      0.84      0.84      5060\n",
            "\n",
            "[[1991  539]\n",
            " [ 274 2256]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-2528\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-2528/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-2528/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3/checkpoint-2528 (score: 0.8388861636975136).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2528, training_loss=0.3366475158099887, metrics={'train_runtime': 855.9483, 'train_samples_per_second': 94.538, 'train_steps_per_second': 2.953, 'total_flos': 6652927479187200.0, 'train_loss': 0.3366475158099887, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lr = 5e-5\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"/content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr5\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 5e-5,\n",
        "    fp16 = True, # enable this when using V100 or T4 GPU\n",
        "    per_device_train_batch_size = 16, # up to 64 on 16GB with max len of 128\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n",
        "    num_train_epochs= 4,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 25\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnw37HR1yGN1",
        "outputId": "ea13a6c0-b8d7-45d2-d89e-f623c5c714b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXdfF64R2C3U",
        "outputId": "98c999fe-d0fd-43ef-c773-4259b6f81dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fcf7a61cc072840ad32e1a2e8eb230a79b33db68e3f965f8014a52915cab999f.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv2\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/da598d10a62ed68f0b95e0c032d813a008518ba8fe1d02fb191884f844c818ce.97462e17e0f13709a0a977021298c2733cda0cb6787facbeeb0b53199a7e73bf\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O61n24EI2GcJ",
        "outputId": "813a8686-393a-4fa9-cd15-a66206fb0f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 20230\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 2528\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1265' max='2528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1265/2528 06:44 < 06:44, 3.12 it/s, Epoch 2.00/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.703500</td>\n",
              "      <td>0.699528</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.702600</td>\n",
              "      <td>0.693183</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67      2530\n",
            "           1       0.00      0.00      0.00      2530\n",
            "\n",
            "    accuracy                           0.50      5060\n",
            "   macro avg       0.25      0.50      0.33      5060\n",
            "weighted avg       0.25      0.50      0.33      5060\n",
            "\n",
            "[[2530    0]\n",
            " [2530    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr5/checkpoint-632\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr5/checkpoint-632/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr5/checkpoint-632/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67      2530\n",
            "           1       0.00      0.00      0.00      2530\n",
            "\n",
            "    accuracy                           0.50      5060\n",
            "   macro avg       0.25      0.50      0.33      5060\n",
            "weighted avg       0.25      0.50      0.33      5060\n",
            "\n",
            "[[2530    0]\n",
            " [2530    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr5/checkpoint-1264\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr5/checkpoint-1264/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr5/checkpoint-1264/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1570\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCHEDULER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Size"
      ],
      "metadata": {
        "id": "zJJSGEHh6cBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lr = 3e-5\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"/content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 5e-5,\n",
        "    fp16 = True, # enable this when using V100 or T4 GPU\n",
        "    per_device_train_batch_size = 64, # up to 64 on 16GB with max len of 128\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n",
        "    num_train_epochs= 4,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 25\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZcBUqkd6g4p",
        "outputId": "1c300490-2679-412b-9ea6-9e64cf2c4681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1v-SbuH7CAG",
        "outputId": "5dae75b2-eb94-45fb-aa99-24714e163029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fcf7a61cc072840ad32e1a2e8eb230a79b33db68e3f965f8014a52915cab999f.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv2\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/da598d10a62ed68f0b95e0c032d813a008518ba8fe1d02fb191884f844c818ce.97462e17e0f13709a0a977021298c2733cda0cb6787facbeeb0b53199a7e73bf\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XCArIXbC7GkX",
        "outputId": "d3f04500-c18f-4332-9fc6-d0b8446b278c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 20230\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 632\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='632' max='632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [632/632 11:15, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.413399</td>\n",
              "      <td>0.793102</td>\n",
              "      <td>0.793874</td>\n",
              "      <td>0.798324</td>\n",
              "      <td>0.793874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.368295</td>\n",
              "      <td>0.819969</td>\n",
              "      <td>0.820158</td>\n",
              "      <td>0.821509</td>\n",
              "      <td>0.820158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.376949</td>\n",
              "      <td>0.831510</td>\n",
              "      <td>0.832411</td>\n",
              "      <td>0.839676</td>\n",
              "      <td>0.832411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.381000</td>\n",
              "      <td>0.391117</td>\n",
              "      <td>0.835410</td>\n",
              "      <td>0.836166</td>\n",
              "      <td>0.842460</td>\n",
              "      <td>0.836166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.73      0.78      2530\n",
            "           1       0.76      0.85      0.81      2530\n",
            "\n",
            "    accuracy                           0.79      5060\n",
            "   macro avg       0.80      0.79      0.79      5060\n",
            "weighted avg       0.80      0.79      0.79      5060\n",
            "\n",
            "[[1854  676]\n",
            " [ 367 2163]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-158\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-158/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-158/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.79      0.81      2530\n",
            "           1       0.80      0.85      0.83      2530\n",
            "\n",
            "    accuracy                           0.82      5060\n",
            "   macro avg       0.82      0.82      0.82      5060\n",
            "weighted avg       0.82      0.82      0.82      5060\n",
            "\n",
            "[[1993  537]\n",
            " [ 373 2157]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-316\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-316/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-316/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.76      0.82      2530\n",
            "           1       0.79      0.91      0.84      2530\n",
            "\n",
            "    accuracy                           0.83      5060\n",
            "   macro avg       0.84      0.83      0.83      5060\n",
            "weighted avg       0.84      0.83      0.83      5060\n",
            "\n",
            "[[1921  609]\n",
            " [ 239 2291]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-474\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-474/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-474/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.77      0.82      2530\n",
            "           1       0.80      0.90      0.85      2530\n",
            "\n",
            "    accuracy                           0.84      5060\n",
            "   macro avg       0.84      0.84      0.84      5060\n",
            "weighted avg       0.84      0.84      0.84      5060\n",
            "\n",
            "[[1944  586]\n",
            " [ 243 2287]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-632\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-632/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-632/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs64/checkpoint-632 (score: 0.8354097125902815).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=632, training_loss=0.3454498550559901, metrics={'train_runtime': 676.7653, 'train_samples_per_second': 119.569, 'train_steps_per_second': 0.934, 'total_flos': 6652927479187200.0, 'train_loss': 0.3454498550559901, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of Epochs"
      ],
      "metadata": {
        "id": "JDQYvhEA93fc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V97q5vlUyZp4",
        "outputId": "acd94244-4986-4575-ddb3-10277b274317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"/content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528\",\n",
              "  \"architectures\": [\n",
              "    \"BertForSequenceClassification\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": 0,\n",
              "    \"1\": 1\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"0\": 0,\n",
              "    \"1\": 1\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"problem_type\": \"single_label_classification\",\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.16.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 64000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#load the best model\n",
        "best_model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528\", return_dict=True)\n",
        "best_model.config.label2id = label_map\n",
        "best_model.config.id2label = label_map\n",
        "\n",
        "#get the hyperparameters of the best model\n",
        "best_model.config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zppnDQjXyZp5",
        "outputId": "b2c352ce-87cc-40e6-b5ac-983b4734bef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using amp half precision backend\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 20230\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 3160\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3160' max='3160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3160/3160 17:53, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.253300</td>\n",
              "      <td>0.371263</td>\n",
              "      <td>0.839912</td>\n",
              "      <td>0.839921</td>\n",
              "      <td>0.839998</td>\n",
              "      <td>0.839921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.208600</td>\n",
              "      <td>0.400368</td>\n",
              "      <td>0.848550</td>\n",
              "      <td>0.848617</td>\n",
              "      <td>0.849230</td>\n",
              "      <td>0.848617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.158800</td>\n",
              "      <td>0.448430</td>\n",
              "      <td>0.847351</td>\n",
              "      <td>0.847431</td>\n",
              "      <td>0.848163</td>\n",
              "      <td>0.847431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.105000</td>\n",
              "      <td>0.546589</td>\n",
              "      <td>0.860069</td>\n",
              "      <td>0.860079</td>\n",
              "      <td>0.860178</td>\n",
              "      <td>0.860079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.621424</td>\n",
              "      <td>0.857061</td>\n",
              "      <td>0.857312</td>\n",
              "      <td>0.859839</td>\n",
              "      <td>0.857312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84      2530\n",
            "           1       0.83      0.85      0.84      2530\n",
            "\n",
            "    accuracy                           0.84      5060\n",
            "   macro avg       0.84      0.84      0.84      5060\n",
            "weighted avg       0.84      0.84      0.84      5060\n",
            "\n",
            "[[2106  424]\n",
            " [ 386 2144]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-632\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-632/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-632/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.83      0.85      2530\n",
            "           1       0.83      0.87      0.85      2530\n",
            "\n",
            "    accuracy                           0.85      5060\n",
            "   macro avg       0.85      0.85      0.85      5060\n",
            "weighted avg       0.85      0.85      0.85      5060\n",
            "\n",
            "[[2094  436]\n",
            " [ 330 2200]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-1264\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-1264/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-1264/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84      2530\n",
            "           1       0.83      0.87      0.85      2530\n",
            "\n",
            "    accuracy                           0.85      5060\n",
            "   macro avg       0.85      0.85      0.85      5060\n",
            "weighted avg       0.85      0.85      0.85      5060\n",
            "\n",
            "[[2086  444]\n",
            " [ 328 2202]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-1896\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-1896/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-1896/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.85      0.86      2530\n",
            "           1       0.85      0.87      0.86      2530\n",
            "\n",
            "    accuracy                           0.86      5060\n",
            "   macro avg       0.86      0.86      0.86      5060\n",
            "weighted avg       0.86      0.86      0.86      5060\n",
            "\n",
            "[[2155  375]\n",
            " [ 333 2197]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5060\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.82      0.85      2530\n",
            "           1       0.83      0.90      0.86      2530\n",
            "\n",
            "    accuracy                           0.86      5060\n",
            "   macro avg       0.86      0.86      0.86      5060\n",
            "weighted avg       0.86      0.86      0.86      5060\n",
            "\n",
            "[[2063  467]\n",
            " [ 255 2275]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-3160\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-3160/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-3160/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16/checkpoint-2528 (score: 0.8600694106469552).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3160, training_loss=0.15114933176885678, metrics={'train_runtime': 1073.6471, 'train_samples_per_second': 94.212, 'train_steps_per_second': 2.943, 'total_flos': 8316282682291200.0, 'train_loss': 0.15114933176885678, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"/content/drive/MyDrive/AI701/Classifying_Translationese/20-11/lr3bs16\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 3e-5,\n",
        "    fp16 = True,\n",
        "    per_device_train_batch_size = 16,\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    num_train_epochs= 5,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 123\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = best_model,\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "  )\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Test Data and Evaluate"
      ],
      "metadata": {
        "id": "VZwTus5E_XJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Test Data"
      ],
      "metadata": {
        "id": "o1Jw-JTJgzCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load test data and evaluate\n",
        "\n",
        "# ar_ht_en_test = open('/content/drive/MyDrive/AI701/Classifying_Translationese/data/test.en_ref.ar').read().splitlines()\n",
        "# ar_ht_fr_test = open('/content/drive/MyDrive/AI701/Classifying_Translationese/data/test.fr_ref.ar').read().splitlines()\n",
        "\n",
        "# #load french and english data to translate\n",
        "# en_test = open('/content/drive/MyDrive/AI701/Classifying_Translationese/data/ac-test.en').read().splitlines()\n",
        "# fr_test = open('/content/drive/MyDrive/AI701/Classifying_Translationese/data/ac-test.fr').read().splitlines()"
      ],
      "metadata": {
        "id": "iE_sNXBa_VSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from googletrans import Translator\n",
        "# translator = Translator()\n",
        "# from deep_translator import GoogleTranslator\n",
        "# deep_translator_fr = GoogleTranslator(source = 'fr', target = 'ar')\n",
        "# deep_translator_en = GoogleTranslator(source = 'en', target = 'ar')"
      ],
      "metadata": {
        "id": "h0ZnGOD4EU4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #translate to arabic in batches\n",
        "# traslations = []\n",
        "# n = len(en_test)//100\n",
        "# for i in range(n):\n",
        "#   traslations.append(deep_translator_en.translate_batch(en_test[i*100:(i+1)*100]))\n",
        "# traslations.append(deep_translator_en.translate_batch(en_test[n*100:], source='en', target='ar'))\n",
        "# ar_mt_en_test = [item for sublist in traslations for item in sublist]\n",
        "\n",
        "# traslations = []\n",
        "# n = len(fr_test)//100\n",
        "# for i in range(n):\n",
        "#   traslations.append(deep_translator_fr.translate_batch(fr_test[i*100:(i+1)*100]))\n",
        "# traslations.append(deep_translator_fr.translate_batch(fr_test[n*100:]))\n",
        "# ar_mt_fr_test = [item for sublist in traslations for item in sublist]"
      ],
      "metadata": {
        "id": "3S9t_oPYEfl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## make one dataframe for english and the corresponding machine and human translations\n",
        "# ar_en_test = pd.DataFrame({'en': en_test, 'ar_mt': ar_mt_en_test, 'ar_ht': ar_ht_en_test})\n",
        "\n",
        "# #remove english duplicates\n",
        "# ar_en_test = ar_en_test.drop_duplicates(subset=['en'])\n",
        "\n",
        "# #filter rows where mt is the same as ht\n",
        "# ar_en_test = ar_en_test[ar_en_test['ar_mt'] != ar_en_test['ar_ht']]\n",
        "\n",
        "# ## make one dataframe for french and the corresponding machine and human translations\n",
        "# ar_fr_test = pd.DataFrame({'fr': fr_test, 'ar_mt': ar_mt_fr_test, 'ar_ht': ar_ht_fr_test})\n",
        "\n",
        "# #remove french duplicates\n",
        "# ar_fr_test = ar_fr_test.drop_duplicates(subset=['fr'])\n",
        "\n",
        "# #filter rows where mt is the same as ht\n",
        "# ar_fr_test = ar_fr_test[ar_fr_test['ar_mt'] != ar_fr_test['ar_ht']]"
      ],
      "metadata": {
        "id": "jL5Gl4bNHzl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ar_en_test.to_csv('ar_en_test.csv')\n",
        "# ar_fr_test.to_csv('ar_fr_test.csv')"
      ],
      "metadata": {
        "id": "G7A3-dT5WMiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load And Evaluate"
      ],
      "metadata": {
        "id": "J_kNHaHlhCJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ar_en_test = pd.read_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/ar_en_test.csv')\n",
        "ar_fr_test = pd.read_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/ar_fr_test.csv')"
      ],
      "metadata": {
        "id": "vo-jKUBWfNnd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(ar_fr_test)\n",
        "np.mean(ar_fr_test['ar_ht'].apply(lambda x: len(x.split())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byk3_qnRdJQG",
        "outputId": "70f32537-c751-49cc-e673-87a32953f7f7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.96450079239303"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = ClassificationDataset(\n",
        "    np.concatenate((ar_en_test['ar_ht'], ar_en_test['ar_mt'], ar_fr_test['ar_ht'], ar_fr_test['ar_mt']), axis=0).tolist(),\n",
        "    np.concatenate((np.zeros(len(ar_en_test)), np.ones(len(ar_en_test)), np.zeros(len(ar_fr_test)), np.ones(len(ar_fr_test))), axis=0).tolist(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGLcOsZEZHuT",
        "outputId": "05085f9a-1cdf-4916-da8c-de2d70172804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fcf7a61cc072840ad32e1a2e8eb230a79b33db68e3f965f8014a52915cab999f.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv2\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/af6611146fcbc110b4f831c0428e1fbacc46834e6be67ad005d38282b3a55e56.92809ffe5e568c38fb02e34451b1f9b856d049d10a8f967626ebace17c6bc1c9\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/2c79f1586b3719b467d24700b10ea39810a708e15a96d07faac98e6de8e583d2.40f02d215737071e47e240eb2941705eb18edf27b0126deabe245f3f19f2ee24\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/eadd29c2f1c1a9561439797b9dc30dd8a23f506fd13fde84b93b5fa3bde392f7.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/9b92fc3002bc77d6c3214a307a407638a9ac0ecb7045096be9599828a5dd2126.8d69c2d6da3751176a19c831b3642f8679a3ff9825be1c07f365a65e652e865c\n",
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fcf7a61cc072840ad32e1a2e8eb230a79b33db68e3f965f8014a52915cab999f.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv2\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "print(classification_report(predictions.label_ids,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "s3N0O3UDZRyT",
        "outputId": "7966994a-80d5-43d2-9a50-6da396c87880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 12530\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [98/98 00:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82      6265\n",
            "           1       0.81      0.83      0.82      6265\n",
            "\n",
            "    accuracy                           0.82     12530\n",
            "   macro avg       0.82      0.82      0.82     12530\n",
            "weighted avg       0.82      0.82      0.82     12530\n",
            "\n",
            "[[5054 1211]\n",
            " [1047 5218]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82      6265\n",
            "           1       0.81      0.83      0.82      6265\n",
            "\n",
            "    accuracy                           0.82     12530\n",
            "   macro avg       0.82      0.82      0.82     12530\n",
            "weighted avg       0.82      0.82      0.82     12530\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions['source_lang'] = np.concatenate((['en'] * (2*len(ar_en_test)), ['fr'] * (2*len(ar_fr_test))), axis =0)"
      ],
      "metadata": {
        "id": "H6mPKPsjJyc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.to_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/predictions_on_test.csv')"
      ],
      "metadata": {
        "id": "Zm7uQlSFE1_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model on all English data then evaluate on French"
      ],
      "metadata": {
        "id": "G1DonBBawCPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ClassificationDataset(\n",
        "    np.concatenate((ar_en['ar_ht'], ar_en['ar_mt']), axis=0).tolist(),\n",
        "    np.concatenate((np.zeros(len(ar_en)), np.ones(len(ar_en))), axis=0).tolist(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )\n",
        "test_dataset = ClassificationDataset(\n",
        "    np.concatenate((ar_fr_test['ar_ht'], ar_fr_test['ar_mt']), axis=0).tolist(),\n",
        "    np.concatenate((np.zeros(len(ar_fr_test)), np.ones(len(ar_fr_test))), axis=0).tolist(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )"
      ],
      "metadata": {
        "id": "GGgX2Nxk8snE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= \"/content/drive/MyDrive/AI701/Classifying_Translationese/all_en_model\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 2e-5,\n",
        "    fp16 = False,\n",
        "    per_device_train_batch_size = 64,\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    num_train_epochs= 2,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 123\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "metadata": {
        "id": "FjBr3Qiicvef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "a6b5e622cf22488e9ddc21c9b56e1a80",
            "5126d429a8c644bfa210d80b65050ea2",
            "3e720ddcd6834aa396345365cd491de9",
            "8f68aa8824cc4a90ae9155799bdbaf37",
            "b5f2ef386d904433ac2645f5632695ae",
            "d72be0d3df674d06bbabea56ae572d98",
            "3fa28ede8a6b4feea7c1eb0ad0f829bf",
            "c36def98ac204d96942ad8256f6ee2ae",
            "6041437f34f84bed8118cb233d8dddbd",
            "8b557c3b1f6748daa9d4de54623cefd4",
            "676e7a592b4c4a758fe6156d38cdc94b"
          ]
        },
        "id": "yQGuZdp5_YyN",
        "outputId": "d623795f-4fbc-4ed0-fc3f-15624c0c0934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6b5e622cf22488e9ddc21c9b56e1a80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lM6MadVUdAb_",
        "outputId": "f02dfa06-c74e-46a7-ef50-84cab7357611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12636\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 198\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='198' max='198' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [198/198 03:50, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.739956</td>\n",
              "      <td>0.569168</td>\n",
              "      <td>0.574485</td>\n",
              "      <td>0.578353</td>\n",
              "      <td>0.574485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.822659</td>\n",
              "      <td>0.569982</td>\n",
              "      <td>0.578288</td>\n",
              "      <td>0.584844</td>\n",
              "      <td>0.578288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 6310\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.69      0.62      3155\n",
            "           1       0.60      0.46      0.52      3155\n",
            "\n",
            "    accuracy                           0.57      6310\n",
            "   macro avg       0.58      0.57      0.57      6310\n",
            "weighted avg       0.58      0.57      0.57      6310\n",
            "\n",
            "[[2163  992]\n",
            " [1693 1462]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/all_en_model/checkpoint-99\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/all_en_model/checkpoint-99/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/all_en_model/checkpoint-99/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 6310\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.72      0.63      3155\n",
            "           1       0.61      0.44      0.51      3155\n",
            "\n",
            "    accuracy                           0.58      6310\n",
            "   macro avg       0.58      0.58      0.57      6310\n",
            "weighted avg       0.58      0.58      0.57      6310\n",
            "\n",
            "[[2263  892]\n",
            " [1769 1386]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/all_en_model/checkpoint-198\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/all_en_model/checkpoint-198/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/all_en_model/checkpoint-198/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/AI701/Classifying_Translationese/all_en_model/checkpoint-198 (score: 0.5699817535142482).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=198, training_loss=0.4752465450402462, metrics={'train_runtime': 234.0783, 'train_samples_per_second': 107.964, 'train_steps_per_second': 0.846, 'total_flos': 2077919559705600.0, 'train_loss': 0.4752465450402462, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model on French Data and Test on English"
      ],
      "metadata": {
        "id": "yB10n02ajYrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ClassificationDataset(\n",
        "    np.concatenate((ar_fr['ar_ht'], ar_fr['ar_mt']), axis=0).tolist(),\n",
        "    np.concatenate((np.zeros(len(ar_fr)), np.ones(len(ar_fr))), axis=0).tolist(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )\n",
        "test_dataset = ClassificationDataset(\n",
        "    np.concatenate((ar_en_test['ar_ht'], ar_en_test['ar_mt']), axis=0).tolist(),\n",
        "    np.concatenate((np.zeros(len(ar_en_test)), np.ones(len(ar_en_test))), axis=0).tolist(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )"
      ],
      "metadata": {
        "id": "KsIUGErbjf6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= \"/content/drive/MyDrive/AI701/Classifying_Translationese/all_fr_model\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 2e-5,\n",
        "    fp16 = False,\n",
        "    per_device_train_batch_size = 64,\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    num_train_epochs= 2,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 123\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETwL9f2Cj_iM",
        "outputId": "b8ca9f47-4a10-4aa0-8d5a-387476a66839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_FoE0PTkIrn",
        "outputId": "d5e65d54-0925-45bd-fbc9-1273c6f14bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fcf7a61cc072840ad32e1a2e8eb230a79b33db68e3f965f8014a52915cab999f.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv2\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/da598d10a62ed68f0b95e0c032d813a008518ba8fe1d02fb191884f844c818ce.97462e17e0f13709a0a977021298c2733cda0cb6787facbeeb0b53199a7e73bf\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6VDHi5U2kOQM",
        "outputId": "ace4b49e-8c91-44b2-92d9-80ab058f0ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12654\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 198\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='198' max='198' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [198/198 03:53, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.685997</td>\n",
              "      <td>0.497439</td>\n",
              "      <td>0.549035</td>\n",
              "      <td>0.583205</td>\n",
              "      <td>0.549035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.827292</td>\n",
              "      <td>0.504196</td>\n",
              "      <td>0.556592</td>\n",
              "      <td>0.598030</td>\n",
              "      <td>0.556592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 6220\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.23      0.34      3110\n",
            "           1       0.53      0.87      0.66      3110\n",
            "\n",
            "    accuracy                           0.55      6220\n",
            "   macro avg       0.58      0.55      0.50      6220\n",
            "weighted avg       0.58      0.55      0.50      6220\n",
            "\n",
            "[[ 711 2399]\n",
            " [ 406 2704]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/all_fr_model/checkpoint-99\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/all_fr_model/checkpoint-99/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/all_fr_model/checkpoint-99/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 6220\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.23      0.34      3110\n",
            "           1       0.53      0.88      0.67      3110\n",
            "\n",
            "    accuracy                           0.56      6220\n",
            "   macro avg       0.60      0.56      0.50      6220\n",
            "weighted avg       0.60      0.56      0.50      6220\n",
            "\n",
            "[[ 720 2390]\n",
            " [ 368 2742]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/AI701/Classifying_Translationese/all_fr_model/checkpoint-198\n",
            "Configuration saved in /content/drive/MyDrive/AI701/Classifying_Translationese/all_fr_model/checkpoint-198/config.json\n",
            "Model weights saved in /content/drive/MyDrive/AI701/Classifying_Translationese/all_fr_model/checkpoint-198/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/AI701/Classifying_Translationese/all_fr_model/checkpoint-198 (score: 0.5041964841764356).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=198, training_loss=0.6133339236481021, metrics={'train_runtime': 234.1968, 'train_samples_per_second': 108.063, 'train_steps_per_second': 0.845, 'total_flos': 2080879559078400.0, 'train_loss': 0.6133339236481021, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bin on sentence length"
      ],
      "metadata": {
        "id": "qJcCH7Yp_aNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions = pd.read_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/predictions_on_test.csv')"
      ],
      "metadata": {
        "id": "AH2N3pqsGJIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pSnFM_lnHEEI",
        "outputId": "cdd29e8b-12e7-4dc4-b8a8-db2f50d69f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    sent  pred  label  \\\n",
              "0                      مجلس الجماعة الاقتصادية الأوروبية     0    0.0   \n",
              "1      حيث أن اعتماد سياسة نقل مشتركة تنطوي من بين أم...     1    0.0   \n",
              "2      3. لا تخضع أنواع النقل المدرجة في الملحق الثان...     0    0.0   \n",
              "3      تبلغ الدول الأعضاء المفوضية الأوروبية بالتدابي...     0    0.0   \n",
              "4                              مفوضية الجماعات الأوروبية     0    0.0   \n",
              "...                                                  ...   ...    ...   \n",
              "12525  بالنظر إلى اللائحة (المفوضية الأوروبية) رقم 21...     1    1.0   \n",
              "12526  وبناء على الطلب المقدم من لوكسمبورغ بتاريخ 25 ...     1    1.0   \n",
              "12527  (2) ينبغي منح هذه الاستثناءات، بناء على طلبها،...     1    1.0   \n",
              "12528  ب) تستفيد فرنسا من الاستثناءات فيما يتعلق بعرض...     1    1.0   \n",
              "12529  وفي نهاية الفترة الانتقالية، تقوم النمسا وفرنس...     1    1.0   \n",
              "\n",
              "       sent_len  \n",
              "0             4  \n",
              "1            36  \n",
              "2            40  \n",
              "3            23  \n",
              "4             3  \n",
              "...         ...  \n",
              "12525        25  \n",
              "12526        10  \n",
              "12527        12  \n",
              "12528        33  \n",
              "12529        13  \n",
              "\n",
              "[12530 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbe9d101-602b-4045-ab13-fb4826c19156\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>pred</th>\n",
              "      <th>label</th>\n",
              "      <th>sent_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>مجلس الجماعة الاقتصادية الأوروبية</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>حيث أن اعتماد سياسة نقل مشتركة تنطوي من بين أم...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3. لا تخضع أنواع النقل المدرجة في الملحق الثان...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>تبلغ الدول الأعضاء المفوضية الأوروبية بالتدابي...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>مفوضية الجماعات الأوروبية</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12525</th>\n",
              "      <td>بالنظر إلى اللائحة (المفوضية الأوروبية) رقم 21...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12526</th>\n",
              "      <td>وبناء على الطلب المقدم من لوكسمبورغ بتاريخ 25 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12527</th>\n",
              "      <td>(2) ينبغي منح هذه الاستثناءات، بناء على طلبها،...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12528</th>\n",
              "      <td>ب) تستفيد فرنسا من الاستثناءات فيما يتعلق بعرض...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12529</th>\n",
              "      <td>وفي نهاية الفترة الانتقالية، تقوم النمسا وفرنس...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12530 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbe9d101-602b-4045-ab13-fb4826c19156')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbe9d101-602b-4045-ab13-fb4826c19156 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbe9d101-602b-4045-ab13-fb4826c19156');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0aa9fe8-83f0-4671-9133-853a6a82e66c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0aa9fe8-83f0-4671-9133-853a6a82e66c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0aa9fe8-83f0-4671-9133-853a6a82e66c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bins = {}\n",
        "\n",
        "max_len = predictions['sent_len'].max()\n",
        "\n",
        "for bin in range(0, max_len//5):\n",
        "    bin_df = predictions[(predictions['sent_len'] >= bin*5) & (predictions['sent_len'] < (bin+1)*5)]\n",
        "    bin_dataset = ClassificationDataset(\n",
        "        bin_df['sent'].tolist(),\n",
        "        bin_df['label'].tolist(),\n",
        "        model_name,\n",
        "        max_len,\n",
        "        label_map)\n",
        "    bins[bin] = accuracy_score(bin_dataset.target, bin_df['pred'].tolist())"
      ],
      "metadata": {
        "id": "pvEDor8PtsPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = []\n",
        "\n",
        "for bin in range(0, max_len//5):\n",
        "    sizes.append(len(predictions[(predictions['sent_len'] >= bin*5) & (predictions['sent_len'] < (bin+1)*5)]))"
      ],
      "metadata": {
        "id": "MCpTsFDb2S9e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bar = plt.bar([x* 5 for x in list(bins.keys())][:15], list(bins.values())[:15], width=4)\n",
        "plt.bar_label(bar,sizes[:15])\n",
        "\n",
        "plt.xlabel(\"Sentence length\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "plt.savefig('bins_total.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "J-mf4X3PZ6Un",
        "outputId": "cab9889e-5b51-4ff1-f7ea-8db139b6ecc8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "predictions = pd.read_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/predictions_on_test.csv')"
      ],
      "metadata": {
        "id": "fV0WdUVdwNT-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions['tokenized_sent_len'] = predictions['sent'].apply(lambda x: len(tok.tokenize(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6GAaoD6NZh0",
        "outputId": "2275e672-d805-4a7f-cf9d-61998521fe81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(predictions['tokenized_sent_len'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-MX5_ygOJf9",
        "outputId": "5a1d47a9-c087-476b-d91d-79bb1bd4b784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.12657621707901"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(predictions['sent_len'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwDDwO_mwlOK",
        "outputId": "7a20c710-9004-4df4-a3ed-63703dd55f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.843335993615323"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze Model on Training Data"
      ],
      "metadata": {
        "id": "F148AItIK6w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best_model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/AI701/Classifying_Translationese/final_model_fr+en/checkpoint-316\", return_dict=True)\n"
      ],
      "metadata": {
        "id": "q2CtGLqpLOqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = trainer.predict(train_dataset)\n",
        "preds = np.argmax(train_predictions.predictions, axis=1)\n",
        "print(classification_report(train_predictions.label_ids,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AjBpkfdQ3Ty",
        "outputId": "05d72673-ce2d-4955-e5ee-1b683fdb0dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98     10115\n",
            "           1       0.98      0.99      0.99     10115\n",
            "\n",
            "    accuracy                           0.98     20230\n",
            "   macro avg       0.99      0.98      0.98     20230\n",
            "weighted avg       0.99      0.98      0.98     20230\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = pd.DataFrame({'sent': train_dataset.text, 'label': train_predictions.label_ids, 'pred': preds})"
      ],
      "metadata": {
        "id": "ufe9Mrk0SA1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions['source_lang'] = np.concatenate((['en'] * (2* len(ar_en_train)), ['fr'] * (2* len(ar_fr_train))), axis =0)"
      ],
      "metadata": {
        "id": "VLtlnBAtS5XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions[train_predictions['label'] != train_predictions['pred']].to_csv('/content/drive/MyDrive/AI701/Classifying_Translationese/data/train_misclassifications.csv')"
      ],
      "metadata": {
        "id": "deGynPkVSrnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYEAivZ9Toyh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "s4VU-wCKyZps",
        "o1Jw-JTJgzCH",
        "J_kNHaHlhCJv"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64aebaff460e4d09aca4b242e2d04b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed1d06ab6db94318aa341f460abda3dc",
              "IPY_MODEL_3b407842f2e44fc88ddb39bd6c571b6c",
              "IPY_MODEL_c79cb1bef7dc438d846365ce463cd050"
            ],
            "layout": "IPY_MODEL_71ea323b4ca0478f946ab1c8dd2d84e7"
          }
        },
        "ed1d06ab6db94318aa341f460abda3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46e992226d9b492b91431f3854e6d409",
            "placeholder": "​",
            "style": "IPY_MODEL_a50d3df77de54a00b412a5a747aaaebc",
            "value": "Downloading: 100%"
          }
        },
        "3b407842f2e44fc88ddb39bd6c571b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ecdc6f7d73a417889907d73130e47e8",
            "max": 543490667,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38e95a1fc5d54ae7828c6175bd617829",
            "value": 543490667
          }
        },
        "c79cb1bef7dc438d846365ce463cd050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4930cb71498b4436af100e0d0f92cca7",
            "placeholder": "​",
            "style": "IPY_MODEL_82d0ea92ab924db285ff061c5f8697a1",
            "value": " 518M/518M [00:21&lt;00:00, 26.3MB/s]"
          }
        },
        "71ea323b4ca0478f946ab1c8dd2d84e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46e992226d9b492b91431f3854e6d409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50d3df77de54a00b412a5a747aaaebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ecdc6f7d73a417889907d73130e47e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e95a1fc5d54ae7828c6175bd617829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4930cb71498b4436af100e0d0f92cca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d0ea92ab924db285ff061c5f8697a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6b5e622cf22488e9ddc21c9b56e1a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5126d429a8c644bfa210d80b65050ea2",
              "IPY_MODEL_3e720ddcd6834aa396345365cd491de9",
              "IPY_MODEL_8f68aa8824cc4a90ae9155799bdbaf37"
            ],
            "layout": "IPY_MODEL_b5f2ef386d904433ac2645f5632695ae"
          }
        },
        "5126d429a8c644bfa210d80b65050ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72be0d3df674d06bbabea56ae572d98",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa28ede8a6b4feea7c1eb0ad0f829bf",
            "value": "Downloading: 100%"
          }
        },
        "3e720ddcd6834aa396345365cd491de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c36def98ac204d96942ad8256f6ee2ae",
            "max": 543490667,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6041437f34f84bed8118cb233d8dddbd",
            "value": 543490667
          }
        },
        "8f68aa8824cc4a90ae9155799bdbaf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b557c3b1f6748daa9d4de54623cefd4",
            "placeholder": "​",
            "style": "IPY_MODEL_676e7a592b4c4a758fe6156d38cdc94b",
            "value": " 518M/518M [00:17&lt;00:00, 31.6MB/s]"
          }
        },
        "b5f2ef386d904433ac2645f5632695ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72be0d3df674d06bbabea56ae572d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa28ede8a6b4feea7c1eb0ad0f829bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c36def98ac204d96942ad8256f6ee2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6041437f34f84bed8118cb233d8dddbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b557c3b1f6748daa9d4de54623cefd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "676e7a592b4c4a758fe6156d38cdc94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}